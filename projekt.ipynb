{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D OSZTALYOZAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import trimesh\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pointnet.dataset import ModelNetDataset, gen_modelnet_id\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from learning3d.models import DGCNN\n",
    "from pointnet.model import PointNetCls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = keras.utils.get_file(\n",
    "    \"modelnet.zip\",\n",
    "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature keszites az SVM-hez, RF-hez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_dimension(mesh):\n",
    "    return mesh.bounding_box.extents\n",
    "def surface_area(mesh):\n",
    "    return mesh.area\n",
    "def volume(mesh):\n",
    "    return mesh.volume\n",
    "def compactness(mesh):\n",
    "    return mesh.volume**2 / mesh.area**3\n",
    "def eccentricity(mesh):\n",
    "    eigenvalues = np.linalg.eigvalsh(np.cov(mesh.vertices.T))\n",
    "    return np.sqrt(eigenvalues[-1] / eigenvalues[0])\n",
    "def genus(mesh):\n",
    "    return mesh.euler_number // 2\n",
    "def euler_characteristic(mesh):\n",
    "    return len(mesh.vertices) - len(mesh.edges) + len(mesh.faces)\n",
    "def num_connected_components(mesh):\n",
    "    return len(mesh.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = \"C:/Users/daneb/.keras/datasets/modelnet_extracted/ModelNet10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes: 100%|██████████| 10/10 [05:03<00:00, 30.33s/it]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(mesh):\n",
    "    features = []\n",
    "    features.extend(bounding_box_dimension(mesh))\n",
    "    features.append(surface_area(mesh))\n",
    "    features.append(volume(mesh))\n",
    "    features.append(compactness(mesh))\n",
    "    features.append(eccentricity(mesh))\n",
    "    features.append(genus(mesh))\n",
    "    features.append(euler_characteristic(mesh))\n",
    "    features.append(num_connected_components(mesh))\n",
    "    return features\n",
    "\n",
    "output_csv = \"modelnet10_features.csv\"\n",
    "with open(output_csv, 'w') as f:\n",
    "    f.write(\"label,bbd_x,bbd_y,bbd_z,s_area,volume,compact,eccent,genus,euler,num_conn\\n\")\n",
    "\n",
    "for class_name in tqdm.tqdm([d for d in os.listdir(d_path) if os.path.isdir(os.path.join(d_path, d))], desc=\"Classes\"):\n",
    "    class_path = os.path.join(d_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue  \n",
    "    for split in ['train']:\n",
    "        split_path = os.path.join(class_path, split)\n",
    "        mesh_files = [file for file in os.listdir(split_path) if file.endswith(('.off'))]\n",
    "        for file in tqdm.tqdm(mesh_files, desc=f\"{class_name}/{split}\", leave=False):\n",
    "            mesh_path = os.path.join(split_path, file)\n",
    "            mesh = trimesh.load(mesh_path)\n",
    "            features = extract_features(mesh)\n",
    "            with open(output_csv, 'a') as f:\n",
    "                f.write(f\"{class_name},{','.join(map(str, features))}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_features_df = pd.read_csv(\"modelnet10_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bbd_x</th>\n",
       "      <th>bbd_y</th>\n",
       "      <th>bbd_z</th>\n",
       "      <th>s_area</th>\n",
       "      <th>volume</th>\n",
       "      <th>compact</th>\n",
       "      <th>eccent</th>\n",
       "      <th>genus</th>\n",
       "      <th>euler</th>\n",
       "      <th>num_conn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>32.256600</td>\n",
       "      <td>54.000500</td>\n",
       "      <td>40.211500</td>\n",
       "      <td>32701.112088</td>\n",
       "      <td>1.531873e+00</td>\n",
       "      <td>6.710543e-14</td>\n",
       "      <td>1.655826</td>\n",
       "      <td>794</td>\n",
       "      <td>-6078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>35.243882</td>\n",
       "      <td>59.489766</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>17020.348330</td>\n",
       "      <td>-2.425319e-12</td>\n",
       "      <td>1.192978e-36</td>\n",
       "      <td>1.825356</td>\n",
       "      <td>167</td>\n",
       "      <td>-1184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>27.559100</td>\n",
       "      <td>66.929100</td>\n",
       "      <td>21.535390</td>\n",
       "      <td>12562.333554</td>\n",
       "      <td>2.142343e+04</td>\n",
       "      <td>2.315086e-04</td>\n",
       "      <td>3.291839</td>\n",
       "      <td>2038</td>\n",
       "      <td>-32221</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>61.000040</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>36.574800</td>\n",
       "      <td>18972.581747</td>\n",
       "      <td>3.620864e+04</td>\n",
       "      <td>1.919752e-04</td>\n",
       "      <td>2.749974</td>\n",
       "      <td>268</td>\n",
       "      <td>-5531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>31.647400</td>\n",
       "      <td>61.016600</td>\n",
       "      <td>29.846396</td>\n",
       "      <td>7520.084685</td>\n",
       "      <td>1.447286e+03</td>\n",
       "      <td>4.925390e-06</td>\n",
       "      <td>2.456193</td>\n",
       "      <td>-21</td>\n",
       "      <td>-46055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      bbd_x      bbd_y      bbd_z        s_area        volume  \\\n",
       "0  bathtub  32.256600  54.000500  40.211500  32701.112088  1.531873e+00   \n",
       "1  bathtub  35.243882  59.489766  22.750000  17020.348330 -2.425319e-12   \n",
       "2  bathtub  27.559100  66.929100  21.535390  12562.333554  2.142343e+04   \n",
       "3  bathtub  61.000040  61.000000  36.574800  18972.581747  3.620864e+04   \n",
       "4  bathtub  31.647400  61.016600  29.846396   7520.084685  1.447286e+03   \n",
       "\n",
       "        compact    eccent  genus  euler  num_conn  \n",
       "0  6.710543e-14  1.655826    794  -6078         0  \n",
       "1  1.192978e-36  1.825356    167  -1184         0  \n",
       "2  2.315086e-04  3.291839   2038 -32221         4  \n",
       "3  1.919752e-04  2.749974    268  -5531         0  \n",
       "4  4.925390e-06  2.456193    -21 -46055         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label       0\n",
      "bbd_x       0\n",
      "bbd_y       0\n",
      "bbd_z       0\n",
      "s_area      0\n",
      "volume      0\n",
      "compact     0\n",
      "eccent      0\n",
      "genus       0\n",
      "euler       0\n",
      "num_conn    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mesh_features_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mesh_features_df.drop(columns=['label']) \n",
    "y = mesh_features_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "chair          889\n",
      "sofa           680\n",
      "bed            515\n",
      "monitor        465\n",
      "table          392\n",
      "toilet         344\n",
      "desk           200\n",
      "dresser        200\n",
      "night_stand    200\n",
      "bathtub        106\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bathtub       0.00      0.00      0.00        32\n",
      "         bed       0.48      0.08      0.14       155\n",
      "       chair       0.41      0.93      0.57       267\n",
      "        desk       0.00      0.00      0.00        60\n",
      "     dresser       0.48      0.17      0.25        60\n",
      "     monitor       0.37      0.19      0.25       139\n",
      " night_stand       0.67      0.03      0.06        60\n",
      "        sofa       0.36      0.82      0.50       204\n",
      "       table       0.00      0.00      0.00       118\n",
      "      toilet       0.22      0.02      0.04       103\n",
      "\n",
      "    accuracy                           0.39      1198\n",
      "   macro avg       0.30      0.22      0.18      1198\n",
      "weighted avg       0.33      0.39      0.28      1198\n",
      "\n",
      "Accuracy: 39.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daneb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\daneb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\daneb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "svm = make_pipeline(StandardScaler(), SVC(kernel='rbf', random_state=42))\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bathtub       0.57      0.38      0.45        32\n",
      "         bed       0.73      0.68      0.70       155\n",
      "       chair       0.88      0.93      0.91       267\n",
      "        desk       0.53      0.35      0.42        60\n",
      "     dresser       0.85      0.77      0.81        60\n",
      "     monitor       0.78      0.79      0.79       139\n",
      " night_stand       0.73      0.72      0.72        60\n",
      "        sofa       0.67      0.86      0.75       204\n",
      "       table       0.73      0.64      0.68       118\n",
      "      toilet       0.89      0.79      0.84       103\n",
      "\n",
      "    accuracy                           0.77      1198\n",
      "   macro avg       0.74      0.69      0.71      1198\n",
      "weighted avg       0.76      0.77      0.76      1198\n",
      "\n",
      "Accuracy: 76.63%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet\n",
    "[Forras - 1](https://arxiv.org/pdf/1612.00593)\n",
    "[Forras - 2](https://keras.io/examples/vision/pointnet/)\n",
    "[Forras - 3](https://github.com/fxia22/pointnet.pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated train.txt and test.txt successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(d_path, 'train.txt'), 'w') as train_f, \\\n",
    "     open(os.path.join(d_path, 'test.txt'), 'w') as test_f:\n",
    "    for cls in os.listdir(d_path):\n",
    "        cls_path = os.path.join(d_path, cls)\n",
    "        if os.path.isdir(cls_path):  \n",
    "            for split in ['train', 'test']:  \n",
    "                split_path = os.path.join(cls_path, split)\n",
    "                if os.path.isdir(split_path):  \n",
    "                    for file in os.listdir(split_path):\n",
    "                        if file.endswith('.ply'):  \n",
    "                            line = f\"{cls}/{split}/{file}\\n\"\n",
    "                            if split == 'train':\n",
    "                                train_f.write(line)\n",
    "                            else:\n",
    "                                test_f.write(line)\n",
    "\n",
    "print(\"Generated train.txt and test.txt successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('pointnet.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = \"C:/Users/daneb/.keras/datasets/modelnet_extracted/ModelNet10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n",
      "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
     ]
    }
   ],
   "source": [
    "gen_modelnet_id(d_path)\n",
    "\n",
    "train_dataset = ModelNetDataset(root=d_path, split='train', npoints=1024, data_augmentation=True)\n",
    "\n",
    "test_dataset = ModelNetDataset(root=d_path, split='test', npoints=1024, data_augmentation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_off_to_ply(off_path, ply_path):\n",
    "    mesh = trimesh.load(off_path)\n",
    "    mesh.export(ply_path)\n",
    "\n",
    "for root, dirs, files in os.walk(d_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.off'):\n",
    "            off_file = os.path.join(root, file)\n",
    "            ply_file = off_file.replace('.off', '.ply')\n",
    "            convert_off_to_ply(off_file, ply_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n",
      "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ModelNetDataset(root=d_path, split='train', npoints=1024, data_augmentation=True)\n",
    "test_dataset = ModelNetDataset(root=d_path, split='test', npoints=1024, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "npoints = 1024\n",
    "epochs = 13\n",
    "learning_rate = 0.0005 \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ModelNet10:\n",
      ".DS_Store\n",
      "bathtub\n",
      "bed\n",
      "chair\n",
      "desk\n",
      "dresser\n",
      "monitor\n",
      "night_stand\n",
      "README.txt\n",
      "sofa\n",
      "table\n",
      "test.txt\n",
      "toilet\n",
      "train.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of ModelNet10:\")\n",
    "for item in os.listdir(d_path):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/13], Loss: 1.3622, Accuracy: 56.80%\n",
      "Test Accuracy after Epoch [1/13]: 59.36%\n",
      "Epoch [2/13], Loss: 1.0038, Accuracy: 67.28%\n",
      "Test Accuracy after Epoch [2/13]: 66.63%\n",
      "Epoch [3/13], Loss: 0.8712, Accuracy: 71.03%\n",
      "Test Accuracy after Epoch [3/13]: 58.48%\n",
      "Epoch [4/13], Loss: 0.8027, Accuracy: 73.99%\n",
      "Test Accuracy after Epoch [4/13]: 69.16%\n",
      "Epoch [5/13], Loss: 0.7524, Accuracy: 74.79%\n",
      "Test Accuracy after Epoch [5/13]: 70.15%\n",
      "Epoch [6/13], Loss: 0.7408, Accuracy: 75.12%\n",
      "Test Accuracy after Epoch [6/13]: 69.05%\n",
      "Epoch [7/13], Loss: 0.7190, Accuracy: 76.05%\n",
      "Test Accuracy after Epoch [7/13]: 73.02%\n",
      "Epoch [8/13], Loss: 0.6788, Accuracy: 76.92%\n",
      "Test Accuracy after Epoch [8/13]: 68.28%\n",
      "Epoch [9/13], Loss: 0.6511, Accuracy: 78.03%\n",
      "Test Accuracy after Epoch [9/13]: 66.52%\n",
      "Epoch [10/13], Loss: 0.6399, Accuracy: 78.55%\n",
      "Test Accuracy after Epoch [10/13]: 69.71%\n",
      "Epoch [11/13], Loss: 0.6436, Accuracy: 78.70%\n",
      "Test Accuracy after Epoch [11/13]: 70.93%\n",
      "Epoch [12/13], Loss: 0.6228, Accuracy: 79.35%\n",
      "Test Accuracy after Epoch [12/13]: 72.58%\n",
      "Epoch [13/13], Loss: 0.6143, Accuracy: 79.35%\n",
      "Test Accuracy after Epoch [13/13]: 71.04%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')  \n",
    "\n",
    "classifier = PointNetCls(k=10)\n",
    "classifier.to(device)  \n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    classifier.train()  \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (points, labels) in enumerate(train_loader):\n",
    "        points, labels = points.float().to(device), labels.long().to(device)\n",
    "        \n",
    "        \n",
    "        points = points.transpose(2, 1)  \n",
    "\n",
    "        labels = labels.squeeze()  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, *_ = classifier(points) \n",
    "\n",
    "        loss = F.cross_entropy(outputs, labels)  \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    classifier.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for points, labels in test_loader:\n",
    "            points, labels = points.float().to(device), labels.long().to(device)\n",
    "            points = points.transpose(2, 1)  \n",
    "\n",
    "            labels = labels.squeeze()  \n",
    "\n",
    "            outputs, *_ = classifier(points)  \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy after Epoch [{epoch+1}/{epochs}]: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNet10Dataset(Dataset):\n",
    "    def __init__(self, d_path, split='train', num_points=1024, txt_file=None):\n",
    "        self.dataset_path = d_path\n",
    "        self.split = split\n",
    "        self.num_points = num_points\n",
    "        self.txt_file = txt_file  \n",
    "        self.mesh_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.classes = sorted([cls for cls in os.listdir(d_path) if os.path.isdir(os.path.join(d_path, cls))])\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "        \n",
    "        self.load_mesh_paths_and_labels()\n",
    "\n",
    "    def load_mesh_paths_and_labels(self):\n",
    "        if not os.path.exists(self.txt_file):\n",
    "            raise FileNotFoundError(f\"File {self.txt_file} does not exist.\")\n",
    "        \n",
    "        with open(self.txt_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                mesh_path = line.strip()\n",
    "                if not mesh_path:\n",
    "                    print(f\"Skipping empty line.\")\n",
    "                    continue\n",
    "                \n",
    "                class_name = mesh_path.split('/')[0]\n",
    "                \n",
    "                if class_name not in self.class_to_idx:\n",
    "                    print(f\"Skipping unknown class: {class_name}\")\n",
    "                    continue\n",
    "                \n",
    "                label = self.class_to_idx[class_name]\n",
    "                \n",
    "                full_path = os.path.join(self.dataset_path, mesh_path)\n",
    "                if not os.path.exists(full_path):\n",
    "                    print(f\"Warning: File {full_path} does not exist.\")\n",
    "                    continue\n",
    "                \n",
    "                self.mesh_paths.append(full_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "        if len(self.mesh_paths) == 0:\n",
    "            raise ValueError(f\"No valid data found in {self.txt_file}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mesh_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mesh_path = self.mesh_paths[idx]\n",
    "        pointcloud = self.load_pointcloud(mesh_path)\n",
    "        label = self.labels[idx]\n",
    "        pointcloud = torch.tensor(pointcloud, dtype=torch.float32).transpose(0, 1)  \n",
    "        return pointcloud, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "    def load_pointcloud(self, path):\n",
    "        mesh = trimesh.load_mesh(path)\n",
    "        pointcloud, _ = trimesh.sample.sample_surface(mesh, self.num_points)\n",
    "        return pointcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "d_path = \"C:/Users/daneb/.keras/datasets/modelnet_extracted/ModelNet10\"\n",
    "train_txt_file = \"C:/Users/daneb/.keras/datasets/modelnet_extracted/ModelNet10/train.txt\"\n",
    "test_txt_file = \"C:/Users/daneb/.keras/datasets/modelnet_extracted/ModelNet10/test.txt\"\n",
    "\n",
    "train_dataset_dgcnn = ModelNet10Dataset(d_path, split='train', num_points=1024, txt_file=train_txt_file)\n",
    "test_dataset_dgcnn = ModelNet10Dataset(d_path, split='test', num_points=1024, txt_file=test_txt_file)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_dgcnn, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_dgcnn, batch_size=32, shuffle=False)\n",
    "\n",
    "pointcloud, label = train_dataset_dgcnn[0]\n",
    "print(pointcloud.shape)  \n",
    "print(label) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN_Classifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10, emb_dims=1024):\n",
    "        super(DGCNN_Classifier, self).__init__()\n",
    "        self.dgcnn = DGCNN(emb_dims=emb_dims)\n",
    "        self.fc1 = torch.nn.Linear(emb_dims, 512)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(256)\n",
    "        self.dp1 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc3 = torch.nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dgcnn(x)  \n",
    "        x = x.max(dim=2)[0]  \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7173, Accuracy: 43.55%\n",
      "Epoch 2, Loss: 0.8947, Accuracy: 70.66%\n",
      "Epoch 3, Loss: 0.5982, Accuracy: 80.83%\n",
      "Epoch 4, Loss: 0.4671, Accuracy: 85.22%\n",
      "Epoch 5, Loss: 0.4014, Accuracy: 86.75%\n",
      "Epoch 6, Loss: 0.3661, Accuracy: 88.27%\n",
      "Epoch 7, Loss: 0.3292, Accuracy: 89.48%\n",
      "Epoch 8, Loss: 0.3131, Accuracy: 89.55%\n",
      "Epoch 9, Loss: 0.3237, Accuracy: 89.55%\n",
      "Epoch 10, Loss: 0.2814, Accuracy: 90.43%\n",
      "Epoch 11, Loss: 0.2842, Accuracy: 90.45%\n",
      "Epoch 12, Loss: 0.2575, Accuracy: 91.86%\n",
      "Epoch 13, Loss: 0.2457, Accuracy: 92.18%\n",
      "Epoch 14, Loss: 0.2228, Accuracy: 92.33%\n",
      "Epoch 15, Loss: 0.2236, Accuracy: 92.53%\n",
      "Epoch 16, Loss: 0.1936, Accuracy: 93.56%\n",
      "Epoch 17, Loss: 0.2212, Accuracy: 92.63%\n",
      "Epoch 18, Loss: 0.2100, Accuracy: 92.71%\n",
      "Epoch 19, Loss: 0.2069, Accuracy: 93.16%\n",
      "Epoch 20, Loss: 0.1892, Accuracy: 93.76%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN_Classifier(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for points, labels in train_loader:\n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        points = points.permute(0, 2, 1)  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(points)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    acc = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"dgcnn_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZARAS, OSSZEGZES\n",
    "Hasznalt adathalmaz: [ModelNet10 - Princeton](http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\")\n",
    "\n",
    "Erintentett modszerek:\n",
    "- SVM\n",
    "- RandomForest\n",
    "- PointNet\n",
    "- DGCNN\n",
    "\n",
    "| Modszer/modell | Pontossag | Bemenet                          |\n",
    "|----------------|-----------|----------------------------------|\n",
    "| SVM            |     39.07%      | Topologiai/Geometriai leirok     |\n",
    "| RandomForest   |     76.63%      | Topologiai/Geometriai leirok     |\n",
    "| PointNet       |     79.35%      | Point Cloud                      |\n",
    "| DGCNN          |     93.56%| Point Cloud, de graf generalodik |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
